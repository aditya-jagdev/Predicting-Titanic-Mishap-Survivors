{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "import math\n",
    "import nltk\n",
    "import numpy as np\n",
    "import operator\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import pydotplus\n",
    "import random\n",
    "import re\n",
    "import seaborn as sns\n",
    "import string\n",
    "import sys\n",
    "import time\n",
    "import warnings\n",
    "import zipfile\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "from gensim import corpora\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "from gensim.models.ldamodel import LdaModel\n",
    "from gensim.models.lsimodel import LsiModel\n",
    "\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.utils import simple_preprocess\n",
    "\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.under_sampling import ClusterCentroids\n",
    "from imblearn.under_sampling import TomekLinks\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "from io import StringIO\n",
    "\n",
    "from IPython.display import Image\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import colors as mcolors\n",
    "from matplotlib import ticker\n",
    "\n",
    "from mlxtend.classifier import StackingClassifier\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem.porter import *\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim\n",
    "\n",
    "from scipy import stats\n",
    "from scipy.cluster import hierarchy as sch\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.datasets import make_moons\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.feature_selection import f_regression\n",
    "from sklearn.feature_selection import f_classif\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import SelectPercentile\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import precision_recall_fscore_support as error_metric\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.tree import plot_tree\n",
    "\n",
    "from string import punctuation\n",
    "\n",
    "from textblob import TextBlob\n",
    "\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "from wordcloud import WordCloud\n",
    "from wordcloud import STOPWORDS\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "np.set_printoptions(threshold=sys.maxsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_transform(value):\n",
    "    return np.log(value) if value > 0 else 0\n",
    "\n",
    "def sqrt_transform(value):\n",
    "    return np.sqrt(value)\n",
    "\n",
    "def boxcox_transform(array):\n",
    "    index_temp = list(array.index).copy()\n",
    "    array_temp = array\n",
    "    array_temp = np.where(array_temp == 0, 0.000000001, array_temp)\n",
    "    return pd.Series(data=stats.boxcox(array_temp)[0],\n",
    "                    index=index_temp) \n",
    "\n",
    "def check_skewness(array):\n",
    "    sns.distplot(array)\n",
    "    print(stats.skew(array))\n",
    "    \n",
    "def show_transformed(array):\n",
    "    array_log = array\n",
    "    array_log = array_log.apply(log_transform)\n",
    "    print(\"Log skew: {0}\".format(stats.skew(array_log)))\n",
    "    sns.distplot(array_log)\n",
    "    plt.show()\n",
    "    \n",
    "    array_sqrt = array\n",
    "    array_sqrt = array_sqrt.apply(sqrt_transform)\n",
    "    print(\"Sqrt skew: {0}\".format(stats.skew(array_sqrt)))\n",
    "    sns.distplot(array_sqrt)\n",
    "    plt.show()\n",
    "    \n",
    "    array_boxcox = boxcox_transform(array)\n",
    "    print(\"Boxcox skew: {0}\".format(stats.skew(array_boxcox)))\n",
    "    sns.distplot(array_boxcox)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"processed data/data.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(columns=['Name', 'SibSp', 'Parch', 'Ticket', \n",
    "                   'Fare', 'Cabin', 'Embarked', 'Title', \n",
    "                   'Title for Age', 'Ticket Prefix', \n",
    "                   'Deck'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Survived              418\n",
       "Title Social            0\n",
       "Family Size             0\n",
       "CD2LF Distr             0\n",
       "CD2LF Pop               0\n",
       "CDensity                0\n",
       "Cabin Shared With       0\n",
       "Fare Individual         0\n",
       "Ticket Shared With      0\n",
       "Age                     0\n",
       "Sex                     0\n",
       "Pclass                  0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Age'] = pd.Series( boxcox_transform( data['Age'].astype(int) )).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Fare Individual'] = data['Fare Individual'].apply(lambda x: round(x, ndigits=2))\n",
    "data['Fare Individual'] = pd.Series(boxcox_transform(data['Fare Individual']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Cabin Shared With'] = data['Cabin Shared With'].map({1: 1,\n",
    "                                                          2: 2,\n",
    "                                                          3: 3,\n",
    "                                                          4: 3,\n",
    "                                                          5: 3,\n",
    "                                                          6: 4,\n",
    "                                                          7: 4})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Family Size'] = data['Family Size'].map({1: 1,\n",
    "                                                2: 2,\n",
    "                                                3: 2,\n",
    "                                                4: 3,\n",
    "                                                5: 4,\n",
    "                                                6: 4,\n",
    "                                                7: 4,\n",
    "                                                8: 4,\n",
    "                                                11: 4})\n",
    "\n",
    "data['Ticket Shared With'] = data['Ticket Shared With'].apply(lambda x: 5 if x not in [1, 2, 3, 4] else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.get_dummies(data, columns=['Pclass', 'Sex', 'Title Social', 'Ticket Shared With', 'Cabin Shared With', 'Family Size'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Fare Individual</th>\n",
       "      <th>CDensity</th>\n",
       "      <th>CD2LF Pop</th>\n",
       "      <th>CD2LF Distr</th>\n",
       "      <th>Pclass_1</th>\n",
       "      <th>Pclass_2</th>\n",
       "      <th>Pclass_3</th>\n",
       "      <th>Pclass_4</th>\n",
       "      <th>...</th>\n",
       "      <th>Ticket Shared With_4</th>\n",
       "      <th>Ticket Shared With_5</th>\n",
       "      <th>Cabin Shared With_1.0</th>\n",
       "      <th>Cabin Shared With_2.0</th>\n",
       "      <th>Cabin Shared With_3.0</th>\n",
       "      <th>Cabin Shared With_4.0</th>\n",
       "      <th>Family Size_1</th>\n",
       "      <th>Family Size_2</th>\n",
       "      <th>Family Size_3</th>\n",
       "      <th>Family Size_4</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11.378487</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.715410</td>\n",
       "      <td>2.373239</td>\n",
       "      <td>2.553812</td>\n",
       "      <td>2.178697</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17.498220</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.448082</td>\n",
       "      <td>0.776442</td>\n",
       "      <td>1.058785</td>\n",
       "      <td>2.704327</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13.001950</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.878758</td>\n",
       "      <td>2.373239</td>\n",
       "      <td>2.553812</td>\n",
       "      <td>2.178697</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16.417590</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.615653</td>\n",
       "      <td>0.776442</td>\n",
       "      <td>1.058785</td>\n",
       "      <td>2.704327</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>16.417590</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.909327</td>\n",
       "      <td>3.100000</td>\n",
       "      <td>2.980769</td>\n",
       "      <td>1.953125</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Age  Survived  Fare Individual  CDensity  CD2LF Pop  \\\n",
       "PassengerId                                                              \n",
       "1            11.378487       0.0         2.715410  2.373239   2.553812   \n",
       "2            17.498220       1.0         6.448082  0.776442   1.058785   \n",
       "3            13.001950       1.0         2.878758  2.373239   2.553812   \n",
       "4            16.417590       1.0         5.615653  0.776442   1.058785   \n",
       "5            16.417590       0.0         2.909327  3.100000   2.980769   \n",
       "\n",
       "             CD2LF Distr  Pclass_1  Pclass_2  Pclass_3  Pclass_4  ...  \\\n",
       "PassengerId                                                       ...   \n",
       "1               2.178697         0         0         0         1  ...   \n",
       "2               2.704327         1         0         0         0  ...   \n",
       "3               2.178697         0         0         0         1  ...   \n",
       "4               2.704327         1         0         0         0  ...   \n",
       "5               1.953125         0         0         1         0  ...   \n",
       "\n",
       "             Ticket Shared With_4  Ticket Shared With_5  \\\n",
       "PassengerId                                               \n",
       "1                               0                     0   \n",
       "2                               0                     0   \n",
       "3                               0                     0   \n",
       "4                               0                     0   \n",
       "5                               0                     0   \n",
       "\n",
       "             Cabin Shared With_1.0  Cabin Shared With_2.0  \\\n",
       "PassengerId                                                 \n",
       "1                                0                      0   \n",
       "2                                0                      1   \n",
       "3                                0                      0   \n",
       "4                                0                      1   \n",
       "5                                0                      0   \n",
       "\n",
       "             Cabin Shared With_3.0  Cabin Shared With_4.0  Family Size_1  \\\n",
       "PassengerId                                                                \n",
       "1                                0                      0              0   \n",
       "2                                0                      0              0   \n",
       "3                                0                      0              1   \n",
       "4                                0                      0              0   \n",
       "5                                0                      0              1   \n",
       "\n",
       "             Family Size_2  Family Size_3  Family Size_4  \n",
       "PassengerId                                               \n",
       "1                        1              0              0  \n",
       "2                        1              0              0  \n",
       "3                        0              0              0  \n",
       "4                        1              0              0  \n",
       "5                        0              0              0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('processed data/data_for_training.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
